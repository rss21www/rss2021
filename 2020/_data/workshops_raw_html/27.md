<p>
Physical contact used to be a problem in robotic manipulation research. Today,
it seems to be the solution. For example, object manipulation behaviours which
maximize contact and exploit contact constraints with the environment are very
robust. Furthermore, physical interaction with the environment facilitates
perception by creating rich, informative sensory signals that would otherwise
not be present. Evidence both in humans and robots shows that these two
principles of (i) exploiting contact constraints and (ii) interactive
perception are essential for robust manipulation and perception under
uncertainty. Yet, autonomous generation of the underlying behaviours or
chaining them together remains a challenge. Existing, traditional contact
models are based on a powerful and concise mathematical formalization. They
make assumptions such as stable point contacts, Coulomb friction or other
simplifications that ensure computational tractability. While this allows
multi-contact planning, many of these assumptions do not translate well into
the real world that is riddled by uncertainty. 
</p>

<p>
The central question of this workshop is how we bridge between the traditional,
model-based approaches and the promising contact-seeking behaviours for robust
manipulation and perception. We will discuss this with researchers from
different areas such as autonomous grasping and manipulation, robotic hand
development, soft manipulation, whole-body control for legged robots and
interactive perception. All of them share that at their core they are concerned
with the problem of making and breaking contact. We aim to discuss and share
the lessons learned from decades of research on manipulation of the environment
via physical contact.
</p>
