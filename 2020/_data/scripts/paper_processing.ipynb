{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import DictReader\n",
    "import os\n",
    "desktop = os.path.join(os.path.join(os.path.expanduser('~')), 'Desktop')\n",
    "file_path = 'Macintosh HD/Users/jrheee/Desktop/' \n",
    "csvfile_name = 'CameraReadyIntegration.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv():\n",
    "    with open(csvfile_name, 'r') as csvfile:\n",
    "        reader = DictReader(csvfile, delimiter=';')\n",
    "\n",
    "        for row in reader:\n",
    "            print('cp \"%s/CameraReadySubmission/%s\" papers/%03i_CMT%04i.pdf' % (row['PaperID'],row['PaperFile'], int(row['PaperOrder']), int(row['PaperID'])))\n",
    "            print('cp \"%s/CameraReadySubmission/%s\" agreements/%03i_CMT%04i.pdf' % (row['PaperID'],row['AgreementFile'], int(row['PaperOrder']), int(row['PaperID'])))\n",
    "def summaries():\n",
    "    with open(csvfile_name, 'r') as csvfile:\n",
    "        reader = DictReader(csvfile, delimiter=';')\n",
    "\n",
    "        for row in reader:\n",
    "            for key, value in row.items():\n",
    "                if value=='[Not Answered]':\n",
    "                    row[key]=''\n",
    "\n",
    "            print('--------------------------')\n",
    "            print('ID:', row['PaperID'])\n",
    "            print('Proceedings Number:', row['PaperOrder'])\n",
    "            print('PheedLoop link:', row['PaperPheedLink'])\n",
    "            print('title:', row['PaperTitle'])\n",
    "            if row['AuthorLinks']:\n",
    "                print('authors:', row['AuthorLinks'])\n",
    "            else:\n",
    "                print('authors:', row['AuthorNames'])\n",
    "            if row['PaperWebpage']:\n",
    "                print('webpage:', row['PaperWebpage'])\n",
    "            if row['SupplementaryVideo']:\n",
    "                print('video:', row['SupplementaryVideo'])\n",
    "            if row['SupplementarySoftware']:\n",
    "                print('software:', row['SupplementarySoftware'])\n",
    "\n",
    "            print('abstract:', row['Abstract'])\n",
    "\n",
    "            if row['ReviewAuthorConsent']:\n",
    "                for r in range(1,4):\n",
    "                    if row['Review%iConsent' % (r)]:\n",
    "                        print('Review %i:' % (r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CameraReadyIntegration.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fe63a31c49f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#mv()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a9e915aa5b9a>\u001b[0m in \u001b[0;36msummaries\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cp \"%s/CameraReadySubmission/%s\" agreements/%03i_CMT%04i.pdf'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PaperID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AgreementFile'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PaperOrder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PaperID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CameraReadyIntegration.csv'"
     ]
    }
   ],
   "source": [
    "summaries()\n",
    "#mv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperID</th>\n",
       "      <th>RAND</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>PaperOrder</th>\n",
       "      <th>PaperSession</th>\n",
       "      <th>PaperPheedLink</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>AuthorNames</th>\n",
       "      <th>Files</th>\n",
       "      <th>...</th>\n",
       "      <th>ReviewAuthorConsent</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "      <th>Review1Consent</th>\n",
       "      <th>Review1</th>\n",
       "      <th>Review2Consent</th>\n",
       "      <th>Review2</th>\n",
       "      <th>Review3Consent</th>\n",
       "      <th>Review3</th>\n",
       "      <th>Review4Consent</th>\n",
       "      <th>Review4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1284</td>\n",
       "      <td>0.934857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planning and Execution using Inaccurate Models...</td>\n",
       "      <td>Models used in modern planning problems to sim...</td>\n",
       "      <td>Anirudh Vemula (Carnegie Mellon University)*; ...</td>\n",
       "      <td>RSS2020_Author_Agreement.pdf (112293 bytes); c...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper presents a method for planning in d...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper proposes an approach that interleav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The paper tackles an important and interesting...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.761728</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swoosh! Rattle! Thump! - Actions that Sound</td>\n",
       "      <td>Truly intelligent agents need to capture the i...</td>\n",
       "      <td>Dhiraj Gandhi (Carnegie Mellon University)*; A...</td>\n",
       "      <td>RSS2020_Author_Agreement.pdf (378966 bytes); _...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper provides insights on the importance...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>Overall comments: The submission is highly ori...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This is a very nice, very clear paper. It make...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1313</td>\n",
       "      <td>0.046701</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Visual Reasoning: Learning to Predict Act...</td>\n",
       "      <td>In this paper, we propose a deep convolutional...</td>\n",
       "      <td>Danny Driess (Machine Learning and Robotics La...</td>\n",
       "      <td>rss2020.pdf (5274789 bytes); release.pdf (9025...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper addresses an important issue in man...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>The paper is well written and presents an inte...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper presents an interesting solution to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.366346</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elaborating on Learned Demonstrations with Tem...</td>\n",
       "      <td>Most current methods for learning from demonst...</td>\n",
       "      <td>Craig Innes (University of Edinburgh)*; Subram...</td>\n",
       "      <td>RSS_2020_Camera_Ready.pdf (5618147 bytes); RSS...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>•\\tOriginality: The paper makes an original co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The paper is well written and structured.  The...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>This paper addresses a failing of the traditio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1332</td>\n",
       "      <td>0.193274</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-revisiting Coverage Task with Minimal Disc...</td>\n",
       "      <td>A theoretically complete solution to the optim...</td>\n",
       "      <td>Tong Yang (Zhejiang University)*; Jaime Valls ...</td>\n",
       "      <td>min_removal_RSS.pdf (4726069 bytes); yt002.pdf...</td>\n",
       "      <td>...</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agreement accepted</td>\n",
       "      <td>\\r\\nContribution:\\r\\n\\r\\nThe main contribution...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper presents a theoretical and rigorous...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This paper focuses on achieving full non-revis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PaperID      RAND  Unnamed: 2  PaperOrder  PaperSession  PaperPheedLink  \\\n",
       "0     1284  0.934857           1           1             1             NaN   \n",
       "1     1174  0.761728           2           2             1             NaN   \n",
       "2     1313  0.046701           3           3             1             NaN   \n",
       "3       44  0.366346           4           4             1             NaN   \n",
       "4     1332  0.193274           5           5             1             NaN   \n",
       "\n",
       "                                          PaperTitle  \\\n",
       "0  Planning and Execution using Inaccurate Models...   \n",
       "1        Swoosh! Rattle! Thump! - Actions that Sound   \n",
       "2  Deep Visual Reasoning: Learning to Predict Act...   \n",
       "3  Elaborating on Learned Demonstrations with Tem...   \n",
       "4  Non-revisiting Coverage Task with Minimal Disc...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Models used in modern planning problems to sim...   \n",
       "1  Truly intelligent agents need to capture the i...   \n",
       "2  In this paper, we propose a deep convolutional...   \n",
       "3  Most current methods for learning from demonst...   \n",
       "4  A theoretically complete solution to the optim...   \n",
       "\n",
       "                                         AuthorNames  \\\n",
       "0  Anirudh Vemula (Carnegie Mellon University)*; ...   \n",
       "1  Dhiraj Gandhi (Carnegie Mellon University)*; A...   \n",
       "2  Danny Driess (Machine Learning and Robotics La...   \n",
       "3  Craig Innes (University of Edinburgh)*; Subram...   \n",
       "4  Tong Yang (Zhejiang University)*; Jaime Valls ...   \n",
       "\n",
       "                                               Files  ... ReviewAuthorConsent  \\\n",
       "0  RSS2020_Author_Agreement.pdf (112293 bytes); c...  ...                 NaN   \n",
       "1  RSS2020_Author_Agreement.pdf (378966 bytes); _...  ...  Agreement accepted   \n",
       "2  rss2020.pdf (5274789 bytes); release.pdf (9025...  ...  Agreement accepted   \n",
       "3  RSS_2020_Camera_Ready.pdf (5618147 bytes); RSS...  ...  Agreement accepted   \n",
       "4  min_removal_RSS.pdf (4726069 bytes); yt002.pdf...  ...  Agreement accepted   \n",
       "\n",
       "  Unnamed: 18      Review1Consent  \\\n",
       "0         NaN  Agreement accepted   \n",
       "1         NaN  Agreement accepted   \n",
       "2         NaN  Agreement accepted   \n",
       "3         NaN                 NaN   \n",
       "4         NaN  Agreement accepted   \n",
       "\n",
       "                                             Review1      Review2Consent  \\\n",
       "0  This paper presents a method for planning in d...  Agreement accepted   \n",
       "1  This paper provides insights on the importance...  Agreement accepted   \n",
       "2  This paper addresses an important issue in man...  Agreement accepted   \n",
       "3  •\\tOriginality: The paper makes an original co...                 NaN   \n",
       "4  \\r\\nContribution:\\r\\n\\r\\nThe main contribution...                 NaN   \n",
       "\n",
       "                                             Review2      Review3Consent  \\\n",
       "0  This paper proposes an approach that interleav...                 NaN   \n",
       "1  Overall comments: The submission is highly ori...  Agreement accepted   \n",
       "2  The paper is well written and presents an inte...  Agreement accepted   \n",
       "3  The paper is well written and structured.  The...  Agreement accepted   \n",
       "4  This paper presents a theoretical and rigorous...                 NaN   \n",
       "\n",
       "                                             Review3  Review4Consent Review4  \n",
       "0  The paper tackles an important and interesting...             NaN     NaN  \n",
       "1  This is a very nice, very clear paper. It make...             NaN     NaN  \n",
       "2  This paper presents an interesting solution to...             NaN     NaN  \n",
       "3  This paper addresses a failing of the traditio...             NaN     NaN  \n",
       "4  This paper focuses on achieving full non-revis...             NaN     NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "proceedings = pd.read_csv(desktop + '/' + csvfile_name, delimiter = ';')\n",
    "display(proceedings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format:  \n",
    "\n",
    "---\n",
    "layout: paper\n",
    "title: \"A Fast Stochastic Contact Model for Planar Pushing and Grasping: Theory and Experimental Validation\"\n",
    "comments: true\n",
    "invisible: true\n",
    "---\n",
    "*[Anirudh Vemula](https://vvanirudh.github.io/), [Yash Oza](https://www.ri.cmu.edu/ri-people/yash-oza/), [J. Andrew Bagnell](http://robotwhisperer.org/), [Maxim Likhachev](http://www.cs.cmu.edu/~maxim/index.html)*\n",
    "{: style=\"color:gray; font-size: 120%; text-align: center;\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_header(paper_file, paper_title, nl  = '\\n'):\n",
    "    sep = ('---')\n",
    "    paper_file.write(sep + nl)\n",
    "    paper_file.write('layout: paper' + nl)\n",
    "    paper_file.write('title: \"' + paper_title + '\"' + nl)\n",
    "    paper_file.write('invisible: true' + nl)\n",
    "    paper_file.write(sep + nl)\n",
    "    \n",
    "def generate_authors(paper_file, authors, nl  = '\\n', link = True):\n",
    "    authors = authors.lstrip()\n",
    "    if link:\n",
    "        authors = parse_authors(authors)\n",
    "    authors = authors.replace('*', '')\n",
    "    paper_file.write('*' + authors + '*' + nl)\n",
    "    paper_file.write('{: style=\"color:black; font-size: 120%; text-align: center;\"}' + nl)\n",
    "    paper_file.write(nl)\n",
    "    return authors\n",
    "    \n",
    "def parse_authors(authors):\n",
    "    authors_list = authors.split(')')\n",
    "    authors_list = [a + ')' for a in authors_list]\n",
    "    authors_list.pop()\n",
    "    for idx, author in enumerate(authors_list):\n",
    "        if 'http' not in author:\n",
    "            authors_list[idx] = author.replace('(', '(http://')\n",
    "            \n",
    "    authors = ', '.join(authors_list)\n",
    "    authors = authors.replace('\\r\\n', '')\n",
    "    if ', ,' in authors:\n",
    "        authors = authors.replace(', ,', ', ')\n",
    "    if '] (' in authors:\n",
    "        while '] (' in authors:\n",
    "            authors = authors.replace('] (', '](')\n",
    "    return authors\n",
    "\n",
    "def generate_abstract(paper_file, abstract, nl = '\\n', p_id = 1):\n",
    "    paper_file.write('### Abstract' + nl)\n",
    "    if (p_id == 21) or (p_id == 63):\n",
    "        paper_file.write('<html> <script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"> MathJax.Hub.Config({ tex2jax: {inlineMath: [[\\'$\\',\\'$\\']], processEscapes: true}}); </script>')\n",
    "    else:\n",
    "        paper_file.write('<html>')\n",
    "    paper_file.write('<p style=\"color:gray; font-size: 100%; text-align: justified;\">' + nl)\n",
    "    paper_file.write(abstract + nl)\n",
    "    paper_file.write('</p></html>')\n",
    "    #paper_file.write('{: style=\"color:gray; font-size: 120%; text-align: justified;\"}')\n",
    "    paper_file.write(nl)\n",
    "    paper_file.write(nl)\n",
    "    \n",
    "def generate_video(paper_file, link, youtube = True, nl = '\\n'):\n",
    "    paper_file.write('### Supplementary Video' + nl)\n",
    "    link = parse_video_string(link)\n",
    "    if youtube:\n",
    "        paper_file.write('<iframe width=\"100%\" height=\"400\" src=\"https://www.youtube.com/embed/' +\n",
    "                         link + \n",
    "                         ' \" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>' + nl)\n",
    "    if not youtube:\n",
    "        paper_file.write('<iframe width=\"100%\" height=\"400\" src=\"https://player.vimeo.com/video/' +\n",
    "                         link + ' \" frameborder=\"0\" allow=\" encrypted-media\" allowfullscreen></iframe>' + nl)\n",
    "    paper_file.write(nl)\n",
    "    \n",
    "# <iframe src=\"https://player.vimeo.com/video/{video_id}\" width=\"{video_width}\" height=\"{video_height}\" frameborder=\"0\" title=\"{video_title}\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>\n",
    "    \n",
    "def parse_video_string(link):\n",
    "    if '\\r' in link:\n",
    "        link = link.split('\\r')[0]\n",
    "    link = link.split('/')[-1]\n",
    "    if 'watch' in link:\n",
    "        link = link.split('=')[-1]\n",
    "    return link\n",
    "\n",
    "\n",
    "def generate_supplementary_row(paper_file, link, width, img_type):\n",
    "    paper_file.write('<td style=\"width: ' + str(width) + '%; text-align: center;\"><a href=\"')\n",
    "    paper_file.write(str(link) + '\">')\n",
    "    paper_file.write('<img src=\"{{ site.baseurl }}/images/' + img_type + '_link.png\"\\n')\n",
    "    if img_type != 'pheedloop':\n",
    "        paper_file.write('width = \"50\"  height = \"60\"/> </a> </td>')\n",
    "    if img_type == 'pheedloop':\n",
    "        paper_file.write('width = \"70\"  height = \"60\"/> </a> </td>')\n",
    "    paper_file.write('\\n\\n')\n",
    "\n",
    "def generate_supplementary_info(paper_file, paper_df, nl='\\n', embed_video = False):\n",
    "    webpage = 'http' in str(paper_df['PaperWebpage'])\n",
    "    software = 'http' in str(paper_df['SupplementarySoftware'])\n",
    "    video = False\n",
    "    if not embed_video:\n",
    "        video = ('http' in str(paper_df['SupplementaryVideo']))\n",
    "    \n",
    "    total_links = sum([webpage, software, video]) + 2\n",
    "    width = 20\n",
    "    if total_links == 3:\n",
    "        width = 30\n",
    "    if total_links > 3:\n",
    "        width = 40\n",
    "    \n",
    "    \n",
    "    pdf_link =  'http://www.roboticsproceedings.org/rss16/p'\n",
    "    pdf_link +=  str(int(paper_df['PaperOrder'])).zfill(3) + '.pdf'\n",
    "    \n",
    "    paper_file.write('<table width=\"' + str(width) +'%\"> <tr>' + nl)\n",
    "    \n",
    "    generate_supplementary_row(paper_file, pdf_link, \n",
    "                               width = 20, img_type = 'paper')   \n",
    "    if video:\n",
    "        if paper_df['PaperOrder'] == 70:\n",
    "            for idx, link in enumerate(paper_df['SupplementaryVideo'].split(',')):\n",
    "                generate_supplementary_row(paper_file, str(link), \n",
    "                               width = 20, img_type = 'video')\n",
    "#         if '\\r\\n' in paper_df['SupplementaryVideo']:\n",
    "#             for idx, link in enumerate(paper_df['SupplementaryVideo'].split('\\r\\n')):\n",
    "#                 generate_supplementary_row(paper_file, str(link), \n",
    "#                                width = 20, img_type = 'video')\n",
    "        else:        \n",
    "            generate_supplementary_row(paper_file, paper_df['SupplementaryVideo'], \n",
    "                               width = 20, img_type = 'video')\n",
    "    if webpage:\n",
    "        generate_supplementary_row(paper_file, paper_df['PaperWebpage'], \n",
    "                               width = 20, img_type = 'website')\n",
    "    if software:\n",
    "        generate_supplementary_row(paper_file, paper_df['SupplementarySoftware'], \n",
    "                               width = 20, img_type = 'software')\n",
    "    \n",
    "#     generate_supplementary_row(paper_file, paper_df['PaperPheedLink'], \n",
    "#                                width = 20, img_type = 'pheedloop')\n",
    "        \n",
    "    paper_file.write('</tr></table>')\n",
    "    paper_file.write(nl)\n",
    "    paper_file.write(nl)\n",
    "    \n",
    "def generate_reviews(paper_file, paper_df, nl='\\n'):\n",
    "    for r in range(1,4):\n",
    "        if 'accept' in str(paper_df['Review%iConsent' % (r)]):\n",
    "            paper_file.write('### Paper Reviews' + nl)\n",
    "            break\n",
    "    for r in range(1,5):\n",
    "        if 'accept' in str(paper_df['Review%iConsent' % (r)]):\n",
    "            if r == 4:\n",
    "                print('here')\n",
    "            paper_file.write('<details><summary style=\"font-size:110%; color:#438BCA; cursor: pointer;\"><b> Review ' + str(r) + \n",
    "                             '</b></summary>' + nl)\n",
    "            paper_file.write('<p style=\"color:gray; font-size: 100%; text-align: justified; white-space: pre-line\">' + nl)\n",
    "            review = paper_df['Review%i' % (r)]#.replace('  ', ' <br>')\n",
    "            paper_file.write(review + nl)\n",
    "            paper_file.write('</p> </details>')\n",
    "            paper_file.write(nl)\n",
    "            paper_file.write(nl)\n",
    "            \n",
    "def fix_author_links(links):\n",
    "    if 'http' not in str(links):\n",
    "        return links\n",
    "    if ('[' in str(links)) and ('Answered' not in str(links)):\n",
    "        return links\n",
    "    links = links.replace(')\\r', '),\\r')\n",
    "    authors = links.split(',')\n",
    "    for idx, author in enumerate(authors):\n",
    "        #print(author)\n",
    "        if author == '':\n",
    "            continue\n",
    "        if author[0] != '\\\\':\n",
    "            author = '[' + author\n",
    "        else:\n",
    "            author = author.replace('\\r\\n', '\\r\\n[')\n",
    "        author = author.replace('(', '](')\n",
    "        authors[idx] = author\n",
    "    return ', '.join(authors)\n",
    "\n",
    "def generate_page_footer(paper_file, paper_id):\n",
    "    \n",
    "    paper_file.write('<table width=\"100%\"><tr>')\n",
    "    \n",
    "    if paper_id != 1:\n",
    "        paper_file.write('<td style=\"width: 30%; text-align: center;\">' +\n",
    "                         '<a href=\"{{ site.baseurl }}/program/papers/' + str(paper_id - 1) +\n",
    "                        '\"> <img src=\"{{ site.baseurl }}/images/previous_icon.png\"' + \n",
    "                        ' width = \"120\"  height = \"80\"/> </a> </td>\\n\\n')\n",
    "    else:\n",
    "        paper_file.write('<td style=\"width: 30%; text-align: center;\"> </td> \\n\\n')\n",
    "    \n",
    "    paper_file.write('<td style=\"width: 30%; text-align: center;\">' + \n",
    "                     '<a href=\"{{ site.baseurl }}/program/papers\">' +\n",
    "                     ' <img src=\"{{ site.baseurl }}/images/overview_icon.png\"' +\n",
    "                     ' width = \"120\"  height = \"80\"/> </a> </td> \\n\\n')\n",
    "    \n",
    "    if paper_id != 103:\n",
    "        paper_file.write('<td style=\"width: 30%; text-align: center;\">' +\n",
    "                         '<a href=\"{{ site.baseurl }}/program/papers/' + str(paper_id + 1) +\n",
    "                        '\"> <img src=\"{{ site.baseurl }}/images/next_icon.png\"' + \n",
    "                        ' width = \"100\"  height = \"80\"/> </a> </td> \\n\\n')\n",
    "    else:\n",
    "        paper_file.write('<td style=\"width: 30%; text-align: center;\"> </td> \\n\\n')\n",
    "\n",
    "    paper_file.write('</tr></table>\\n\\n')\n",
    "\n",
    "def generate_virtual_session(paper_file, paper_df, nl = '\\n'):\n",
    "    pheed = paper_df['deeplink']\n",
    "    paper_file.write('### Live Paper Discussion Information' + nl)\n",
    "    paper_file.write('<html>' + nl)\n",
    "    paper_file.write('<table width=\"50%\">' + nl)\n",
    "    paper_file.write('<tr> <th rowspan=\"2\"><a href=\"' + str(pheed) + '\"><img src=\"{{ site.baseurl }}/images/pheedloop_link.png\" width = \"70\"  height = \"70\"/> </a> </th> <th> Start Time </th> <th> End Time </th> </tr>' + nl)\n",
    "    paper_file.write('<tr> <td> ' + paper_df['StartTime'] + ' UTC </td>')\n",
    "    paper_file.write('<td> ' + paper_df['StopTime'] + ' UTC </td></tr>' + nl)\n",
    "    paper_file.write('</table> <br> </html>' + nl)\n",
    "    paper_file.write('### Virtual Conference Presentation' + nl)\n",
    "    paper_file.write('<iframe width=\"100%\" height=\"400\" src=\"https://www.youtube.com/embed/')\n",
    "    paper_file.write(str(paper_df['Youtube']) + '\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n",
    "    paper_file.write(nl + nl)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_embed_video(paper_df):\n",
    "    if ('http' in str(paper_df['SupplementaryVideo'])) and ('youtu' in str(paper_df['SupplementaryVideo'])):\n",
    "        return True\n",
    "    if ('http' in str(paper_df['SupplementaryVideo'])) and ('vimeo' in str(paper_df['SupplementaryVideo'])):\n",
    "        return True\n",
    "    return False     \n",
    "\n",
    "def clean_reviews(review, p_id):\n",
    "    if int(p_id) == 2:\n",
    "        review = review.replace('\\r\\n', ' ', 2)\n",
    "        start = review.find('(1)')\n",
    "        stop  = review.find('results.')\n",
    "        sub_review = review[start:stop].replace('\\r\\n', ' ')\n",
    "        review = review[:start] + sub_review + review[stop:]\n",
    "        return review\n",
    "    if int(p_id) == 17:\n",
    "        return review.replace('failures\\r\\n', 'failures ')\n",
    "\n",
    "def paper_md_file(paper_df, folder='', embed_video=False):\n",
    "    title = paper_df['PaperTitle']\n",
    "    p_id  = paper_df['PaperOrder']\n",
    "    \n",
    "    if p_id == 2:\n",
    "        review = paper_df['Review1']\n",
    "        paper_df['Review1'] = clean_reviews(review, 2)\n",
    "        paper_df['SupplementarySoftware'] = 'https://dhiraj100892.github.io/sound_with_action/'      \n",
    "    if p_id == 17:\n",
    "        review = paper_df['Review1']\n",
    "        paper_df['Review1'] = clean_reviews(review, 17)\n",
    "    if p_id == 18:\n",
    "        paper_df['Review1'] = paper_df['Review1'].replace('the\\r\\n', 'the ')\n",
    "    if p_id == 21:\n",
    "        paper_df['AuthorLinks'] = '[Jiani Li](https://jianili.github.io/jianili/),[Waseem Abbas](http://www.wabbas.com/),[Muddasir Shabbir](https://itu.edu.pk/faculty-itu/muddasir-shabbir/),[Xenofon Koutsoukos](http://www.vuse.vanderbilt.edu/~koutsoxd/)'\n",
    "    if p_id == 23:\n",
    "        paper_df['SupplementaryVideo'] = 'https://www.youtube.com/watch?v=o4zMcKzbY-M'\n",
    "    if p_id == 26:\n",
    "        paper_df['AuthorLinks'] = '[Yulin Yang](http://udel.edu/~yuyang/),[Patrick Geneva](http://udel.edu/~pgeneva/),[Xingxing Zuo](),[Guoquan Huang](http://udel.edu/~ghuang/)'\n",
    "    \n",
    "    if p_id == 65:\n",
    "        paper_df['SupplementarySoftware'] = 'https://github.com/wilson1yan/rlpyt'\n",
    "    \n",
    "    if p_id == 79:\n",
    "        paper_df['SupplementarySoftware'] = ''\n",
    "        paper_df['AuthorLinks'] = '[Antoni Rosinol](https://www.mit.edu/~arosinol/)[Arjun Gupta]()[Marcus Abate]()[Jingnan Shi]()[Luca Carlone](https://lucacarlone.mit.edu/)'\n",
    "    if p_id == 73:\n",
    "        paper_df['AuthorLinks'] = 'Aditya Dhawale (https://adityadhawale.github.io/), Nathan Michael (https://www.rislab.org/nathan-michael)'\n",
    " \n",
    "    \n",
    "    md_file = open(folder + '/'  + str(p_id) + '.md', 'w')\n",
    "    generate_header(paper_file=md_file, paper_title=title)\n",
    "    \n",
    "    # Hard fix paper id 45 (missing author and multiple links...)\n",
    "    if (p_id == 45) and ('David Paulius' in paper_df['AuthorLinks']):\n",
    "        paper_df['AuthorLinks'] = '[David Paulius](https://www.davidpaulius.me),\\r\\n[Nicholas Eales](),\\r\\n[Yu Sun](https://cse.usf.edu/~yusun)'\n",
    "    \n",
    "    paper_df['AuthorLinks'] = fix_author_links(paper_df['AuthorLinks'])\n",
    "    \n",
    "    paper_df['AuthorLinks'] = compare_author_list(paper_df)\n",
    "    \n",
    "    if ('[' in str(paper_df['AuthorLinks'])) and ('Answered' not in str(paper_df['AuthorLinks'])):\n",
    "        generate_authors(paper_file=md_file, authors=paper_df['AuthorLinks'])\n",
    "    else:\n",
    "        generate_authors(paper_file=md_file, authors=paper_df['AuthorNames'], link = False)\n",
    "     \n",
    "    generate_supplementary_info(paper_file=md_file, paper_df=paper_df, embed_video=check_embed_video(paper_df))\n",
    "    \n",
    "    generate_abstract(paper_file=md_file,abstract=paper_df['Abstract'], p_id = p_id )\n",
    "    \n",
    "    \n",
    "    generate_virtual_session(paper_file=md_file, paper_df=paper_df)\n",
    "    \n",
    "    if ('http' in str(paper_df['SupplementaryVideo'])) and ('youtu' in str(paper_df['SupplementaryVideo'])):\n",
    "        generate_video(paper_file=md_file, link=paper_df['SupplementaryVideo'])\n",
    "    if ('http' in str(paper_df['SupplementaryVideo'])) and ('vimeo' in str(paper_df['SupplementaryVideo'])):\n",
    "        generate_video(paper_file=md_file, link=paper_df['SupplementaryVideo'], youtube=False)\n",
    "\n",
    "    if 'accepted' in str(paper_df['ReviewAuthorConsent']):\n",
    "        generate_reviews(paper_file=md_file, paper_df=paper_df)\n",
    "        \n",
    "    generate_page_footer(md_file, p_id)\n",
    "    \n",
    "    md_file.close()\n",
    "    return paper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating MD file for Paper 1\n",
      "4 4\n",
      "Generating MD file for Paper 2\n",
      "Generating MD file for Paper 3\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Ha\n",
      "Generating MD file for Paper 4\n",
      "2 2\n",
      "Generating MD file for Paper 5\n",
      "Generating MD file for Paper 6\n",
      "Generating MD file for Paper 7\n",
      "6 6\n",
      "Generating MD file for Paper 8\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Reardon\n",
      "Generating MD file for Paper 9\n",
      "8 6\n",
      "here\n",
      "Adding Missing Author Vysotska\n",
      "Adding Missing Author Haag\n",
      "Generating MD file for Paper 10\n",
      "5 5\n",
      "Generating MD file for Paper 11\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Jun\n",
      "Generating MD file for Paper 12\n",
      "Generating MD file for Paper 13\n",
      "Generating MD file for Paper 14\n",
      "3 3\n",
      "Generating MD file for Paper 15\n",
      "3 3\n",
      "Generating MD file for Paper 16\n",
      "Generating MD file for Paper 17\n",
      "2 2\n",
      "Generating MD file for Paper 18\n",
      "Generating MD file for Paper 19\n",
      "3 3\n",
      "Generating MD file for Paper 20\n",
      "8 35\n",
      "here\n",
      "Adding Missing Author Taunyazov\n",
      "Adding Missing Author Sng\n",
      "Adding Missing Author Lim\n",
      "Adding Missing Author Hian\n",
      "Adding Missing Author Kuan\n",
      "Adding Missing Author Fatir\n",
      "Adding Missing Author Tee\n",
      "Generating MD file for Paper 21\n",
      "4 4\n",
      "Generating MD file for Paper 22\n",
      "Generating MD file for Paper 23\n",
      "Generating MD file for Paper 24\n",
      "5 5\n",
      "Generating MD file for Paper 25\n",
      "Generating MD file for Paper 26\n",
      "4 4\n",
      "Generating MD file for Paper 27\n",
      "Generating MD file for Paper 28\n",
      "2 2\n",
      "Generating MD file for Paper 29\n",
      "6 6\n",
      "Generating MD file for Paper 30\n",
      "Generating MD file for Paper 31\n",
      "Generating MD file for Paper 32\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Ryou\n",
      "Generating MD file for Paper 33\n",
      "3 3\n",
      "Generating MD file for Paper 34\n",
      "9 9\n",
      "Generating MD file for Paper 35\n",
      "7 7\n",
      "Generating MD file for Paper 36\n",
      "Generating MD file for Paper 37\n",
      "4 4\n",
      "Generating MD file for Paper 38\n",
      "5 58\n",
      "here\n",
      "Adding Missing Author Tan\n",
      "Adding Missing Author Guo\n",
      "Adding Missing Author Zhang\n",
      "Adding Missing Author Sun\n",
      "Generating MD file for Paper 39\n",
      "7 7\n",
      "Generating MD file for Paper 40\n",
      "6 6\n",
      "Generating MD file for Paper 41\n",
      "4 4\n",
      "Generating MD file for Paper 42\n",
      "4 4\n",
      "Generating MD file for Paper 43\n",
      "2 2\n",
      "Generating MD file for Paper 44\n",
      "2 2\n",
      "Generating MD file for Paper 45\n",
      "3 3\n",
      "Generating MD file for Paper 46\n",
      "Generating MD file for Paper 47\n",
      "2 2\n",
      "Generating MD file for Paper 48\n",
      "Generating MD file for Paper 49\n",
      "Generating MD file for Paper 50\n",
      "3 3\n",
      "Generating MD file for Paper 51\n",
      "Generating MD file for Paper 52\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Yu\n",
      "Generating MD file for Paper 53\n",
      "6 6\n",
      "Generating MD file for Paper 54\n",
      "Generating MD file for Paper 55\n",
      "7 6\n",
      "here\n",
      "Adding Missing Author Barnes\n",
      "Generating MD file for Paper 56\n",
      "Generating MD file for Paper 57\n",
      "Generating MD file for Paper 58\n",
      "3 82\n",
      "here\n",
      "Adding Missing Author Djeumou\n",
      "Adding Missing Author Xu\n",
      "Generating MD file for Paper 59\n",
      "Generating MD file for Paper 60\n",
      "2 2\n",
      "Generating MD file for Paper 61\n",
      "5 5\n",
      "Generating MD file for Paper 62\n",
      "Generating MD file for Paper 63\n",
      "2 2\n",
      "Generating MD file for Paper 64\n",
      "6 6\n",
      "Generating MD file for Paper 65\n",
      "5 5\n",
      "Generating MD file for Paper 66\n",
      "Generating MD file for Paper 67\n",
      "10 3\n",
      "here\n",
      "Adding Missing Author Taylor\n",
      "Adding Missing Author Schlafly\n",
      "Adding Missing Author Popovic\n",
      "Adding Missing Author Diniz\n",
      "Adding Missing Author Teich\n",
      "Adding Missing Author Simidchieva\n",
      "Adding Missing Author Clark\n",
      "Generating MD file for Paper 68\n",
      "Generating MD file for Paper 69\n",
      "3 3\n",
      "Generating MD file for Paper 70\n",
      "4 4\n",
      "Generating MD file for Paper 71\n",
      "Generating MD file for Paper 72\n",
      "2 2\n",
      "Generating MD file for Paper 73\n",
      "2 2\n",
      "Generating MD file for Paper 74\n",
      "6 6\n",
      "Generating MD file for Paper 75\n",
      "5 5\n",
      "Generating MD file for Paper 76\n",
      "Generating MD file for Paper 77\n",
      "Generating MD file for Paper 78\n",
      "Generating MD file for Paper 79\n",
      "5 5\n",
      "here\n",
      "Generating MD file for Paper 80\n",
      "6 42\n",
      "here\n",
      "Adding Missing Author Nguyen\n",
      "Adding Missing Author Gopalan\n",
      "Adding Missing Author Patel\n",
      "Adding Missing Author Corsaro\n",
      "Adding Missing Author Pavlick\n",
      "Generating MD file for Paper 81\n",
      "Generating MD file for Paper 82\n",
      "Generating MD file for Paper 83\n",
      "Generating MD file for Paper 84\n",
      "Generating MD file for Paper 85\n",
      "3 35\n",
      "here\n",
      "Adding Missing Author Saxena\n",
      "Adding Missing Author Kroemer\n",
      "Generating MD file for Paper 86\n",
      "3 3\n",
      "Generating MD file for Paper 87\n",
      "Generating MD file for Paper 88\n",
      "Generating MD file for Paper 89\n",
      "Generating MD file for Paper 90\n",
      "3 3\n",
      "Generating MD file for Paper 91\n",
      "3 3\n",
      "Generating MD file for Paper 92\n",
      "4 4\n",
      "Generating MD file for Paper 93\n",
      "4 4\n",
      "Generating MD file for Paper 94\n",
      "2 2\n",
      "Generating MD file for Paper 95\n",
      "3 2\n",
      "here\n",
      "Adding Missing Author Shi\n",
      "Generating MD file for Paper 96\n",
      "Generating MD file for Paper 97\n",
      "3 3\n",
      "Generating MD file for Paper 98\n",
      "Generating MD file for Paper 99\n",
      "2 2\n",
      "Generating MD file for Paper 100\n",
      "7 3\n",
      "here\n",
      "Adding Missing Author Zhang\n",
      "Adding Missing Author Raz\n",
      "Adding Missing Author Barbalata\n",
      "Adding Missing Author Johnson\n",
      "Generating MD file for Paper 101\n",
      "Generating MD file for Paper 102\n",
      "4 4\n",
      "Generating MD file for Paper 103\n",
      "3 3\n"
     ]
    }
   ],
   "source": [
    "# row = proceedings.iloc[17]\n",
    "# paper_md_file(row, desktop + '/Papers/')\n",
    "proceedings = pd.read_csv(desktop + '/' + csvfile_name, delimiter = ';')\n",
    "youtube = pd.read_csv(desktop + '/' + 'youtube_links.csv', delimiter = ';')\n",
    "pheed = pd.read_csv(desktop + '/' + 'paper_links.csv')\n",
    "proceedings['Youtube'] = youtube['YouTube']\n",
    "proceedings['StartTime'] = youtube['SessionStart']\n",
    "proceedings['StopTime'] = youtube['SessionEnd']\n",
    "proceedings['deeplink'] = pheed['deeplink']\n",
    "paper_page_df = pd.DataFrame()\n",
    "new_df = pd.DataFrame()\n",
    "cols = ['PaperID', 'PaperOrder', 'PaperSession', 'PaperPheedLink', 'PaperTitle', 'AuthorNames',]\n",
    "for index, row in proceedings.iterrows():\n",
    "    paper_page_df = paper_page_df.append(row[cols], ignore_index = True)\n",
    "    print('Generating MD file for Paper', row['PaperOrder'])\n",
    "    temp_df = paper_md_file(row, desktop + '/Papers/')\n",
    "    new_df = new_df.append(temp_df)\n",
    "paper_page_df['PaperOrder'] = paper_page_df['PaperOrder'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abstract', 'AgreementFile', 'AuthorLinks', 'AuthorNames', 'Files',\n",
       "       'PaperFile', 'PaperID', 'PaperOrder', 'PaperPheedLink', 'PaperSession',\n",
       "       'PaperTitle', 'PaperWebpage', 'RAND', 'Review1', 'Review1Consent',\n",
       "       'Review2', 'Review2Consent', 'Review3', 'Review3Consent', 'Review4',\n",
       "       'Review4Consent', 'ReviewAuthorConsent', 'StartTime', 'StopTime',\n",
       "       'SupplementarySoftware', 'SupplementaryVideo', 'Unnamed: 16',\n",
       "       'Unnamed: 18', 'Unnamed: 2', 'Youtube'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(new_df.columns)\n",
    "new_df.to_csv(desktop + '/' + 'cameraready.csv',sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['PaperCMR_ID', 'PaperId', 'YouTube', 'PaperSession', 'SessionStart',  ]\n",
    "jens_df = youtube.copy()\n",
    "jens_df['AuthorLinks'] = new_df['AuthorLinks']\n",
    "jens_df['PaperWebpage'] = new_df['PaperWebpage']\n",
    "jens_df['SupplementaryVideo'] = new_df['SupplementaryVideo']\n",
    "jens_df['SupplementarySoftware'] = new_df['SupplementarySoftware']\n",
    "jens_df.to_csv(desktop + '/' + 'cameraready.csv',sep = ',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://pheedloop.com/rss2020/virtual/#session...\n",
       "1      https://pheedloop.com/rss2020/virtual/#session...\n",
       "2      https://pheedloop.com/rss2020/virtual/#session...\n",
       "3      https://pheedloop.com/rss2020/virtual/#session...\n",
       "4      https://pheedloop.com/rss2020/virtual/#session...\n",
       "                             ...                        \n",
       "98     https://pheedloop.com/rss2020/virtual/#session...\n",
       "99     https://pheedloop.com/rss2020/virtual/#session...\n",
       "100    https://pheedloop.com/rss2020/virtual/#session...\n",
       "101    https://pheedloop.com/rss2020/virtual/#session...\n",
       "102    https://pheedloop.com/rss2020/virtual/#session...\n",
       "Name: deeplink, Length: 103, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pheed['deeplink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperCMT_ID</th>\n",
       "      <th>PaperId</th>\n",
       "      <th>YouTube</th>\n",
       "      <th>PaperSession</th>\n",
       "      <th>SessionStart</th>\n",
       "      <th>SessionEnd</th>\n",
       "      <th>ZoomHost</th>\n",
       "      <th>PaperTitle</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>CorrespondingAuthor</th>\n",
       "      <th>CorrespondingEmail</th>\n",
       "      <th>AuthorNames</th>\n",
       "      <th>AuthorLinks</th>\n",
       "      <th>PaperWebpage</th>\n",
       "      <th>SupplementaryVideo</th>\n",
       "      <th>SupplementarySoftware</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1284</td>\n",
       "      <td>1</td>\n",
       "      <td>S7tLYBgZzUM</td>\n",
       "      <td>1</td>\n",
       "      <td>07/14 15:00</td>\n",
       "      <td>07/14 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Planning and Execution using Inaccurate Models...</td>\n",
       "      <td>Models used in modern planning problems to sim...</td>\n",
       "      <td>Anirudh Vemula</td>\n",
       "      <td>avemula1@andrew.cmu.edu</td>\n",
       "      <td>Anirudh Vemula (Carnegie Mellon University)*; ...</td>\n",
       "      <td>[Anirudh Vemula](https://vvanirudh.github.io/)...</td>\n",
       "      <td>https://vvanirudh.github.io/blog/cmax/</td>\n",
       "      <td>https://youtu.be/eQmAeWIhjO8</td>\n",
       "      <td>https://github.com/vvanirudh/CMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1174</td>\n",
       "      <td>2</td>\n",
       "      <td>CLubmYsZsPM</td>\n",
       "      <td>1</td>\n",
       "      <td>07/14 15:00</td>\n",
       "      <td>07/14 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swoosh! Rattle! Thump! - Actions that Sound</td>\n",
       "      <td>Truly intelligent agents need to capture the i...</td>\n",
       "      <td>Dhiraj P Gandhi</td>\n",
       "      <td>g.prakashchand@gmail.com</td>\n",
       "      <td>Dhiraj Gandhi (Carnegie Mellon University)*; A...</td>\n",
       "      <td>[Not Answered]</td>\n",
       "      <td>[Not Answered]</td>\n",
       "      <td>[Not Answered]</td>\n",
       "      <td>[Not Answered]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1313</td>\n",
       "      <td>3</td>\n",
       "      <td>hoKA9csoJNU</td>\n",
       "      <td>1</td>\n",
       "      <td>07/14 15:00</td>\n",
       "      <td>07/14 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Deep Visual Reasoning: Learning to Predict Act...</td>\n",
       "      <td>In this paper, we propose a deep convolutional...</td>\n",
       "      <td>Danny Driess</td>\n",
       "      <td>danny.driess@ipvs.uni-stuttgart.de</td>\n",
       "      <td>Danny Driess (Machine Learning and Robotics La...</td>\n",
       "      <td>[Danny Driess](https://dannydriess.github.io/)...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/i8yyEbbvoEk</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>ZqIsY5Y2cOg</td>\n",
       "      <td>1</td>\n",
       "      <td>07/14 15:00</td>\n",
       "      <td>07/14 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Elaborating on Learned Demonstrations with Tem...</td>\n",
       "      <td>Most current methods for learning from demonst...</td>\n",
       "      <td>Craig A Innes</td>\n",
       "      <td>craig.innes@ed.ac.uk</td>\n",
       "      <td>Craig Innes (University of Edinburgh)*; Subram...</td>\n",
       "      <td>[Craig Innes](http://www.craiginnes.com/); [Su...</td>\n",
       "      <td>https://sites.google.com/view/ltl-dmp-rss-2020/</td>\n",
       "      <td>https://www.youtube.com/watch?v=Te989To-0Rw</td>\n",
       "      <td>https://github.com/craigiedon/ltl_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1332</td>\n",
       "      <td>5</td>\n",
       "      <td>j9u2-fZCQC4</td>\n",
       "      <td>1</td>\n",
       "      <td>07/14 15:00</td>\n",
       "      <td>07/14 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-revisiting Coverage Task with Minimal Disc...</td>\n",
       "      <td>A theoretically complete solution to the optim...</td>\n",
       "      <td>Tong Yang</td>\n",
       "      <td>3140100721@zju.edu.cn</td>\n",
       "      <td>Tong Yang (Zhejiang University)*; Jaime Valls ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/TqFzqGGM06Y</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1305</td>\n",
       "      <td>99</td>\n",
       "      <td>BRda93s1HIg</td>\n",
       "      <td>3</td>\n",
       "      <td>07/16 15:00</td>\n",
       "      <td>07/16 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learning to Slide Unknown Objects with Differe...</td>\n",
       "      <td>We propose a new technique for pushing an unk...</td>\n",
       "      <td>Abdeslam Boularias</td>\n",
       "      <td>boularias@gmail.com</td>\n",
       "      <td>Changkyu Song (Rutgers University); Abdeslam B...</td>\n",
       "      <td>[Abdeslam Boularias](http://rl.cs.rutgers.edu)...</td>\n",
       "      <td>https://sites.google.com/site/changkyusong86/r...</td>\n",
       "      <td>https://www.youtube.com/watch?v=2LQl5Ibeb0E</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1325</td>\n",
       "      <td>100</td>\n",
       "      <td>6tjnh1Yxr_Q</td>\n",
       "      <td>3</td>\n",
       "      <td>07/16 15:00</td>\n",
       "      <td>07/16 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reachable Sets for Safe, Real-Time Manipulator...</td>\n",
       "      <td>For robotic arms to operate in arbitrary envir...</td>\n",
       "      <td>Shreyas Kousik</td>\n",
       "      <td>skousik@umich.edu</td>\n",
       "      <td>Patrick Holmes (University of Michigan); Shrey...</td>\n",
       "      <td>[Patrick Holmes](https://pdholmes.github.io/);...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://youtu.be/ySnux2owlAA</td>\n",
       "      <td>https://github.com/ramvasudevan/arm_planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1212</td>\n",
       "      <td>101</td>\n",
       "      <td>nzLyRHON24E</td>\n",
       "      <td>3</td>\n",
       "      <td>07/16 15:00</td>\n",
       "      <td>07/16 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learning Task-Driven Control Policies via Info...</td>\n",
       "      <td>This paper presents a reinforcement learning a...</td>\n",
       "      <td>Vincent Pacelli</td>\n",
       "      <td>vpacelli@princeton.edu</td>\n",
       "      <td>Vincent Pacelli (Princeton University)*; Aniru...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.youtube.com/watch?v=Mwv0kkRveas</td>\n",
       "      <td>https://github.com/irom-lab/trc-nn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1294</td>\n",
       "      <td>102</td>\n",
       "      <td>JZbc8cLG3dA</td>\n",
       "      <td>3</td>\n",
       "      <td>07/16 15:00</td>\n",
       "      <td>07/16 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Simultaneously Learning Transferable Symbols a...</td>\n",
       "      <td>Enabling robots to learn tasks and follow inst...</td>\n",
       "      <td>Nakul Gopalan</td>\n",
       "      <td>nakulgopalan@gmail.com</td>\n",
       "      <td>Nakul Gopalan (Georgia Tech)*; Eric Rosen (Bro...</td>\n",
       "      <td>[Nakul Gopalan](https://nakulgopalan.github.io...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://vimeo.com/388650000</td>\n",
       "      <td>https://github.com/nakulgopalan/change_point_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>56</td>\n",
       "      <td>103</td>\n",
       "      <td>nOqDxJxizis</td>\n",
       "      <td>3</td>\n",
       "      <td>07/16 15:00</td>\n",
       "      <td>07/16 17:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A social robot mediator to foster collaboratio...</td>\n",
       "      <td>Formation of subgroups and thereby the problem...</td>\n",
       "      <td>Sarah Gillet</td>\n",
       "      <td>sgillet@kth.se</td>\n",
       "      <td>Sarah Gillet (Royal Institute of Technology)*;...</td>\n",
       "      <td>[Sarah Gillet](https://www.kth.se/profile/sgil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PaperCMT_ID  PaperId      YouTube  PaperSession SessionStart  \\\n",
       "0           1284        1  S7tLYBgZzUM             1  07/14 15:00   \n",
       "1           1174        2  CLubmYsZsPM             1  07/14 15:00   \n",
       "2           1313        3  hoKA9csoJNU             1  07/14 15:00   \n",
       "3             44        4  ZqIsY5Y2cOg             1  07/14 15:00   \n",
       "4           1332        5  j9u2-fZCQC4             1  07/14 15:00   \n",
       "..           ...      ...          ...           ...          ...   \n",
       "98          1305       99  BRda93s1HIg             3  07/16 15:00   \n",
       "99          1325      100  6tjnh1Yxr_Q             3  07/16 15:00   \n",
       "100         1212      101  nzLyRHON24E             3  07/16 15:00   \n",
       "101         1294      102  JZbc8cLG3dA             3  07/16 15:00   \n",
       "102           56      103  nOqDxJxizis             3  07/16 15:00   \n",
       "\n",
       "      SessionEnd  ZoomHost                                         PaperTitle  \\\n",
       "0    07/14 17:00       NaN  Planning and Execution using Inaccurate Models...   \n",
       "1    07/14 17:00       NaN        Swoosh! Rattle! Thump! - Actions that Sound   \n",
       "2    07/14 17:00       NaN  Deep Visual Reasoning: Learning to Predict Act...   \n",
       "3    07/14 17:00       NaN  Elaborating on Learned Demonstrations with Tem...   \n",
       "4    07/14 17:00       NaN  Non-revisiting Coverage Task with Minimal Disc...   \n",
       "..           ...       ...                                                ...   \n",
       "98   07/16 17:00       NaN  Learning to Slide Unknown Objects with Differe...   \n",
       "99   07/16 17:00       NaN  Reachable Sets for Safe, Real-Time Manipulator...   \n",
       "100  07/16 17:00       NaN  Learning Task-Driven Control Policies via Info...   \n",
       "101  07/16 17:00       NaN  Simultaneously Learning Transferable Symbols a...   \n",
       "102  07/16 17:00       NaN  A social robot mediator to foster collaboratio...   \n",
       "\n",
       "                                              Abstract CorrespondingAuthor  \\\n",
       "0    Models used in modern planning problems to sim...      Anirudh Vemula   \n",
       "1    Truly intelligent agents need to capture the i...     Dhiraj P Gandhi   \n",
       "2    In this paper, we propose a deep convolutional...        Danny Driess   \n",
       "3    Most current methods for learning from demonst...       Craig A Innes   \n",
       "4    A theoretically complete solution to the optim...           Tong Yang   \n",
       "..                                                 ...                 ...   \n",
       "98    We propose a new technique for pushing an unk...  Abdeslam Boularias   \n",
       "99   For robotic arms to operate in arbitrary envir...      Shreyas Kousik   \n",
       "100  This paper presents a reinforcement learning a...     Vincent Pacelli   \n",
       "101  Enabling robots to learn tasks and follow inst...       Nakul Gopalan   \n",
       "102  Formation of subgroups and thereby the problem...        Sarah Gillet   \n",
       "\n",
       "                     CorrespondingEmail  \\\n",
       "0               avemula1@andrew.cmu.edu   \n",
       "1              g.prakashchand@gmail.com   \n",
       "2    danny.driess@ipvs.uni-stuttgart.de   \n",
       "3                  craig.innes@ed.ac.uk   \n",
       "4                 3140100721@zju.edu.cn   \n",
       "..                                  ...   \n",
       "98                  boularias@gmail.com   \n",
       "99                    skousik@umich.edu   \n",
       "100              vpacelli@princeton.edu   \n",
       "101              nakulgopalan@gmail.com   \n",
       "102                      sgillet@kth.se   \n",
       "\n",
       "                                           AuthorNames  \\\n",
       "0    Anirudh Vemula (Carnegie Mellon University)*; ...   \n",
       "1    Dhiraj Gandhi (Carnegie Mellon University)*; A...   \n",
       "2    Danny Driess (Machine Learning and Robotics La...   \n",
       "3    Craig Innes (University of Edinburgh)*; Subram...   \n",
       "4    Tong Yang (Zhejiang University)*; Jaime Valls ...   \n",
       "..                                                 ...   \n",
       "98   Changkyu Song (Rutgers University); Abdeslam B...   \n",
       "99   Patrick Holmes (University of Michigan); Shrey...   \n",
       "100  Vincent Pacelli (Princeton University)*; Aniru...   \n",
       "101  Nakul Gopalan (Georgia Tech)*; Eric Rosen (Bro...   \n",
       "102  Sarah Gillet (Royal Institute of Technology)*;...   \n",
       "\n",
       "                                           AuthorLinks  \\\n",
       "0    [Anirudh Vemula](https://vvanirudh.github.io/)...   \n",
       "1                                       [Not Answered]   \n",
       "2    [Danny Driess](https://dannydriess.github.io/)...   \n",
       "3    [Craig Innes](http://www.craiginnes.com/); [Su...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "98   [Abdeslam Boularias](http://rl.cs.rutgers.edu)...   \n",
       "99   [Patrick Holmes](https://pdholmes.github.io/);...   \n",
       "100                                                NaN   \n",
       "101  [Nakul Gopalan](https://nakulgopalan.github.io...   \n",
       "102  [Sarah Gillet](https://www.kth.se/profile/sgil...   \n",
       "\n",
       "                                          PaperWebpage  \\\n",
       "0               https://vvanirudh.github.io/blog/cmax/   \n",
       "1                                       [Not Answered]   \n",
       "2                                                  NaN   \n",
       "3      https://sites.google.com/view/ltl-dmp-rss-2020/   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "98   https://sites.google.com/site/changkyusong86/r...   \n",
       "99                                                 NaN   \n",
       "100                                                NaN   \n",
       "101                                                NaN   \n",
       "102                                                NaN   \n",
       "\n",
       "                              SupplementaryVideo  \\\n",
       "0                   https://youtu.be/eQmAeWIhjO8   \n",
       "1                                 [Not Answered]   \n",
       "2                   https://youtu.be/i8yyEbbvoEk   \n",
       "3    https://www.youtube.com/watch?v=Te989To-0Rw   \n",
       "4                   https://youtu.be/TqFzqGGM06Y   \n",
       "..                                           ...   \n",
       "98   https://www.youtube.com/watch?v=2LQl5Ibeb0E   \n",
       "99                  https://youtu.be/ySnux2owlAA   \n",
       "100  https://www.youtube.com/watch?v=Mwv0kkRveas   \n",
       "101                  https://vimeo.com/388650000   \n",
       "102                                          NaN   \n",
       "\n",
       "                                 SupplementarySoftware  \n",
       "0                    https://github.com/vvanirudh/CMAX  \n",
       "1                                       [Not Answered]  \n",
       "2                                                  NaN  \n",
       "3               https://github.com/craigiedon/ltl_diff  \n",
       "4                                                  NaN  \n",
       "..                                                 ...  \n",
       "98                                                 NaN  \n",
       "99        https://github.com/ramvasudevan/arm_planning  \n",
       "100                 https://github.com/irom-lab/trc-nn  \n",
       "101  https://github.com/nakulgopalan/change_point_d...  \n",
       "102                                                NaN  \n",
       "\n",
       "[103 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#display(paper_page_df)\n",
    "youtube = pd.read_csv(desktop + '/' + 'youtube_links.csv', delimiter = ';')\n",
    "display(youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 2\n",
      "here\n",
      "Adding Missing Author Ha\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[Danny Driess](https://dannydriess.github.io/)Jung-Su Ha,  [Marc Toussaint](http://www.marc-toussaint.net/)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_author_list(paper_df):\n",
    "    authors = paper_df['AuthorNames']\n",
    "    links   = paper_df['AuthorLinks']\n",
    "    if '[' not in str(links):\n",
    "        return authors\n",
    "    if 'Answer' in str(links):\n",
    "        return authors\n",
    "    n_authors = len(authors.split(';'))\n",
    "    links = parse_authors(links)\n",
    "    if ',' in links:\n",
    "        n_links = len(links.split(','))\n",
    "    else:\n",
    "        n_links = len(links)\n",
    "    print(n_authors, n_links)\n",
    "    if n_links != n_authors:\n",
    "        print('here')\n",
    "        new_authors = list()\n",
    "        for author in authors.split(';'):\n",
    "            first_name = author.strip().split(' ')[0]\n",
    "            last_name  = author.strip().split(' ')[1]\n",
    "            #print(first_name, last_name)\n",
    "            if last_name not in links:\n",
    "                print('Adding Missing Author', last_name)\n",
    "                #new_authors.append('[' + first_name + ' ' + last_name + ']()')\n",
    "                new_authors.append(first_name + ' ' + last_name + ', ')\n",
    "                continue\n",
    "            for link in links.split(','):\n",
    "                if last_name in link:\n",
    "                    new_authors.append(link)\n",
    "                    continue\n",
    "    else:\n",
    "        return links\n",
    "    return  ''.join(new_authors)\n",
    "\n",
    "compare_author_list(proceedings.iloc[2])\n",
    "# for index, row in proceedings.iterrows():\n",
    "#     authors = compare_author_list(row)\n",
    "# print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"The paper presents an interesting algorithm with a substantial analysis.  However, I do have some suggestions for improvement.\\r\\n\\r\\n1.  The simulation results could be improved. The results illustrate the claims of the algorithm's performance, but they are as abstracted as the underlying problem formulation, thus not adding appreciably to the strength of the paper.  The simulation results would be more effective if they were made to reflect real robots in real environments, attempting to bridge the apparent abstraction-reality gap of the problem formulation.  This could be done with open source robot simulators such as WeBots or ROS-Gazebo.\\r\\n\\r\\n2.  The simulation results do not compare against other algorithms. The authors admit this fact, and excuse themselves given that no other algorithm seems to operate under the same assumptions as theirs. However, it would still be valuable to see the performance of other algorithms for qualitative reasons, even if the underlying assumptions are different.\\r\\n\\r\\n3.  The substance of the paper is the performance analysis of the algorithm.  The authors do a good job of trying to make the analysis digestible and giving intuition for non-experts in this area.  However, it was not clear to this reviewer why a simpler analysis would not suffice.  E.g., if the timing randomness and robot failures were removed, and robots were instead ordered to act one at a time in a discrete time deterministic sense according to the proposed algorithm, it would seem that similar results would be straightforward to obtain.  Then introducing random robot failures on edge traversals would also be relatively straightforward to analyze.  Why then does the random timing present such a challenge?  Some higher level intuition about why this analysis is challenging, and how it becomes simpler under different assumption, would be helpful.\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_reviews(review, p_id):\n",
    "    if int(p_id) == 2:\n",
    "        review = review.replace('\\r\\n', ' ', 2)\n",
    "        start = review.find('(1)')\n",
    "        stop  = review.find('results.')\n",
    "        sub_review = review[start:stop].replace('\\r\\n', ' ')\n",
    "        review = review[:start] + sub_review + review[stop:]\n",
    "        return review\n",
    "    if int(p_id) == 17:\n",
    "        return review.replace('failures\\r\\n', 'failures ')\n",
    "    \n",
    "review = proceedings.iloc[16]['Review1']\n",
    "#display(review.find('(1)'))\n",
    "display(review.find('failures\\r\\n'))\n",
    "clean_reviews(review, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_page_df.to_csv('rss2020_papers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
