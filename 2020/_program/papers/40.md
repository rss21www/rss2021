---
layout: paper
title: "Deep Drone Acrobatics"
invisible: true
---
*[EliaKaufmann](https://kelia.github.io/),  [Antonio Loquercio](https://antonilo.github.io/),  [Rene Ranftl](http://),  [Matthias Müller](https://matthias.pw/),  [Vladlen Koltun](http://vladlen.info/),  [Davide Scaramuzza](http://rpg.ifi.uzh.ch/people_scaramuzza.html)*
{: style="color:black; font-size: 120%; text-align: center;"}

<table width="30%"> <tr>
<td style="width: 20%; text-align: center;"><a href="http://www.roboticsproceedings.org/rss16/p040.pdf"><img src="{{ site.baseurl }}/images/paper_link.png"
width = "50"  height = "60"/> </a> </td>

<td style="width: 20%; text-align: center;"><a href="https://github.com/uzh-rpg/deep_drone_acrobatics"><img src="{{ site.baseurl }}/images/software_link.png"
width = "50"  height = "60"/> </a> </td>

</tr></table>

### Abstract
<html><p style="color:gray; font-size: 100%; text-align: justified;">
Performing acrobatic maneuvers with quadrotors is extremely challenging. Acrobatic flight requires high thrust and extreme angular accelerations that push the platform to its physical limits. Professional drone pilots often measure their level of mastery by flying such maneuvers in competitions. In this paper, we propose to learn a sensorimotor policy that enables an autonomous quadrotor to fly extreme acrobatic maneuvers with only onboard sensing and computation. We train the policy entirely in simulation by leveraging demonstrations from an optimal controller that has access to privileged information. We use appropriate abstractions of the visual input to enable transfer to a real quadrotor. We show that the resulting policy can be directly deployed in the physical world without any fine-tuning on real data. Our methodology has several favorable properties: it does not require a human expert to provide demonstrations, it cannot harm the physical system during training, and it can be used to learn maneuvers that are challenging even for the best human pilots. Our approach enables a physical quadrotor to fly maneuvers such as the Power Loop, the Barrel Roll, and the Matty Flip, during which it incurs accelerations of up to 3g. 
</p></html>

### Live Paper Discussion Information
<html>
<table width="50%">
<tr> <th rowspan="2"><a href="https://pheedloop.com/rss2020/virtual/#session_Hwkubr"><img src="{{ site.baseurl }}/images/pheedloop_link.png" width = "70"  height = "70"/> </a> </th> <th> Start Time </th> <th> End Time </th> </tr>
<tr> <td> 07/15 15:00 UTC </td><td> 07/15 17:00 UTC </td></tr>
</table> <br> </html>
### Virtual Conference Presentation
<iframe width="100%" height="400" src="https://www.youtube.com/embed/VTojN06OR7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Supplementary Video
<iframe width="100%" height="400" src="https://www.youtube.com/embed/2N_wKXQ6MXA " frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Paper Reviews
<details><summary style="font-size:110%; color:#438BCA; cursor: pointer;"><b> Review 1</b></summary>
<p style="color:gray; font-size: 100%; text-align: justified; white-space: pre-line">
This paper proposes a complete learning system which allows a drone to fly acrobatic maneuvers. It learns a sensorimotor agent purely in simulation and performs zero-shot sim-to-real transfer. Impressive results are demonstrated on a real drone. 

This paper is very well written. I was able to fully understand the paper without any difficulties. The paper has a clear technical contribution: preprocessing the raw observations to a feature representation that has smaller sim-to-real gap. This is an important contribution because sim-to-real gap is a universal problem for almost all robotic applications, and is a major obstacle that prevents the use of simulation. This paper presents an effective method, and a different perspective to bridge the gap. The paper showed successful deployment of simulation policy on a real drone and conducted thorough analysis to show the effectiveness of the proposed approach. 

The only thing that I am not confident about is the difficulty of the problem: acrobatic maneuvers for drones, because this is not my immediate research area. If the problem is indeed hard, and this is the first demonstration of such maneuvers, I would vote for acceptance of the paper.
</p> </details>

<details><summary style="font-size:110%; color:#438BCA; cursor: pointer;"><b> Review 2</b></summary>
<p style="color:gray; font-size: 100%; text-align: justified; white-space: pre-line">
The authors propose a deep learning-based approach to training acrobatic motor skills of drones. The key idea is to apply the imitation learning technique (more specifically, DAGGER) to the reference motion while abstracting the visual inputs with feature extractors. The feature extractor computes the motion of salient keypoint in the visual inputs, which would provide better state estimation to the robot. Then all the features (visual inputs, IMU, reference trajectories) are asynchronously fed to the policy network. The reference trajectory is obtained by training a “privileged expert”, which has access to all the ground-truth state information, using MPC. The framework trains the agent solely in the simulation (Gazebo) and transfers to the real world. The authors demonstrate a few agile skills on real drones (AscTec Hummingbird), including a Barrel Roll, a Power Loop, a Matty-Loop.

I am personally impressed by the results presented by this paper: it seems to be pretty agile, without suffering from the sim-to-real transfer. I’m not too familiar with the state-of-the-art in acrobatic motions of drones, but it seems to be a great contribution to have the first acrobatic motion without additional sensory inputs in the robotic community. In this sense, I’m pretty positive about this submission.

On the other hand, the main contribution of the work is the sim-to-real transfer technique using visual points, as claimed by the authors. But their feature tracker (FT) does not improve the results (tracking errors or success rates) in Table I: the drone achieves near-perfect success rates for all four tasks (btw, it seems too obvious that it cannot perform good motor skills without reference motions or IMU). Now Figure 4 provides a bit contradictory results, which are only analyzed in simulation with a specific training/testing setting. Therefore, it is not very clear whether the proposed key contribution, a sim-to-real technique, is crucial in the proposed work.

And the architecture of asynchronous policy networks seems to be standard. It extracts features from raw inputs, concatenates them into history, applies convolutional operations, and generates outputs with feedforward networks. It might not be a very significant contribution to the community.

The paper itself is very well written and reads smoothly.

I would suggest the authors adding the following reference to the paper, which also discusses the sim-to-real of aerial vehicles.
Xu, J., Du, T., Foshey, M., Li, B., Zhu, B., Schulz, A. and Matusik, W., 2019. Learning to fly: computational controller design for hybrid UAVs with reinforcement learning. ACM Transactions on Graphics (TOG), 38(4), pp.1-12.

</p> </details>

<table width="100%"><tr><td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/39"> <img src="{{ site.baseurl }}/images/previous_icon.png" width = "120"  height = "80"/> </a> </td>

<td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers"> <img src="{{ site.baseurl }}/images/overview_icon.png" width = "120"  height = "80"/> </a> </td> 

<td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/41"> <img src="{{ site.baseurl }}/images/next_icon.png" width = "100"  height = "80"/> </a> </td> 

</tr></table>

