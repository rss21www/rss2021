---
layout: paper
title: "Multi-Fidelity Black-Box Optimization for Time-Optimal Quadrotor Maneuvers"
invisible: true
---
*Gilhyun Ryou, [Ezra Tal](http://www.ezratal.net),  [Sertac Karaman](http://karaman.mit.edu)*
{: style="color:black; font-size: 120%; text-align: center;"}

<table width="20%"> <tr>
<td style="width: 20%; text-align: center;"><a href="http://www.roboticsproceedings.org/rss16/p032.pdf"><img src="{{ site.baseurl }}/images/paper_link.png"
width = "50"  height = "60"/> </a> </td>

</tr></table>

### Abstract
<html><p style="color:gray; font-size: 100%; text-align: justified;">
We consider the problem of generating a time-optimal quadrotor trajectory that attains a set of prescribed waypoints. This problem is challenging since the optimal trajectory is located on the boundary of the set of dynamically feasible trajectories. This boundary is hard to model as it involves limitations of the entire system, including hardware and software, in agile high-speed flight. In this work, we propose a multi-fidelity Bayesian optimization framework that models the feasibility constraints based on analytical approximation, numerical simulation, and real-world flight experiments. By combining evaluations at different fidelities, trajectory time is optimized while keeping the number of required costly flight experiments to a minimum. The algorithm is thoroughly evaluated in both simulation and real-world flight experiments at speeds up to 11 m/s. Resulting trajectories were found to be significantly faster than those obtained through minimum-snap trajectory planning.
</p></html>

### Live Paper Discussion Information
<html>
<table width="50%">
<tr> <th rowspan="2"><a href="https://pheedloop.com/rss2020/virtual/#session_ksNlYz"><img src="{{ site.baseurl }}/images/pheedloop_link.png" width = "70"  height = "70"/> </a> </th> <th> Start Time </th> <th> End Time </th> </tr>
<tr> <td> 07/14 15:00 UTC </td><td> 07/14 17:00 UTC </td></tr>
</table> <br> </html>
### Virtual Conference Presentation
<iframe width="100%" height="400" src="https://www.youtube.com/embed/xI-g9dR_TPU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Supplementary Video
<iframe width="100%" height="400" src="https://www.youtube.com/embed/igwULi_H1Kg " frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### Paper Reviews
<details><summary style="font-size:110%; color:#438BCA; cursor: pointer;"><b> Review 2</b></summary>
<p style="color:gray; font-size: 100%; text-align: justified; white-space: pre-line">
Here are a few comments below that may help further improve the paper.

I - Approach and presentation
- The statement 'optimal trajectory is found at boundary of the set of feasible trajectories' doesn't have a reference. I am not sure this is true in general, but even in some specific context an intuitive example or a reference is necessary.
- The first time \alpha appears it is refereed to as the acquisition function. Some more explanation as to what is an acquisition function would benefit readability for a wider audience.
- There is some ambiguity in the overall approach as to what happens online vs offline. Is the approach augmenting the dataset to do incremental learning in an online setting or is the model learned batch style and then deployed to find trajectories, for example, for the real robot. If there is incremental learning is the variational inference performed every time a new data point is added?
- There are a lot of variables and I found myself often going back and forth trying to find their definition. Sometimes the notation maybe inconsistent, for example, l has superscripts and subscripts and have been used interchangeably or their distinction wasn't made clear.
- Trajectory plots are hard to interpret. For instance, Fig 3 is quite small and the distinction in color is hard to see to understand the altitude. Maybe a perspective 3D view would be more helpful or the trajectory with the quadrotor on it at waypoints in various orientations would help ground it.

II - On experiments and practical details
- Going back to the online vs offline ambiguity is it unclear if the learned model is deployed in settings similar to the training data i.e. the boundaries between training and testing is unclear. Given this, how well does the method generalize to problems it has not seen before?
- Result in IVA referring to Fig. 2 is 2%. Maybe this is a typo and it is closer to 20%?
- In Fig. 4 the lower bound on improvement is about 5%. Why was the improvement significantly less here? Any way to know how improvement relates to the problem defined by the desired set of waypoints?
- What were the computational times of the approach?
- It wasn't clear how someone would choose the fidelity levels or even define how many are needed for an application. Also how does the approach scale with increasing number of fidelity classes.

III - Limitations
The authors should consider adding a limitations section where the following could be discussed:
- Is the approach real-time or is the trajectory computed offline and then followed by tracking?
- How is state uncertainty handled?
- How would obstacles be handled?
- The real world flights show the quadrotor moving through free space, how is the tolerance to the desired waypoint verified? With respect to the drone racing challenges mentioned in the introduction typically the quadrotors are required to pass through a set of floating gates.
</p> </details>

<details><summary style="font-size:110%; color:#438BCA; cursor: pointer;"><b> Review 3</b></summary>
<p style="color:gray; font-size: 100%; text-align: justified; white-space: pre-line">
Overall, the paper exposes clearly its objective. It is well written and the contribution is relevant. 
My first point is that it could make a better job a motivating the need to reach exactly the optimum (there are plenty of good reasons for this,
but they are not mentioned here).

My second point is that the paper lacks an important discussion about the cases where the feasibility constraints are wrongly approximated.
In such cases the consequences would of course be rather dramatic, and it seems important to obtain some estimation of how likely this is to occur
with respect to formulation (6).
This brings back to the question of "do we really want the optimum" for uncertain hardware control ? 
I am not saying that identifying the feasibility constraint is not relevant, but the study should somehow discuss how confident the information is.

</p> </details>

<table width="100%"><tr><td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/31"> <img src="{{ site.baseurl }}/images/previous_icon.png" width = "120"  height = "80"/> </a> </td>

<td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers"> <img src="{{ site.baseurl }}/images/overview_icon.png" width = "120"  height = "80"/> </a> </td> 

<td style="width: 30%; text-align: center;"><a href="{{ site.baseurl }}/program/papers/33"> <img src="{{ site.baseurl }}/images/next_icon.png" width = "100"  height = "80"/> </a> </td> 

</tr></table>

